// åç«¯å®æ—¶è¯­éŸ³è½¬å†™æœåŠ¡
import { request } from '@/utils/request';

export interface BackendSpeechResponse {
  success: boolean;
  text?: string;
  error?: string;
  isEnd?: boolean;
}

export interface XunfeiSpeechToTextResponse {
  code: string;
  message: string | null;
  data: {
    success: boolean;
    transcriptionText: string;
    audioDuration: number | null;
    audioFileSize: number;
    audioFormat: string;
    transcriptionStartTime: number;
    transcriptionEndTime: number;
    transcriptionDuration: number;
    confidence: number | null;
    language: string;
    errorMessage: string | null;
    requestId: string;
    originalFileName: string;
  };
  requestId: string | null;
  success: boolean;
}

export interface SpeechToTextResult {
  success: boolean;
  text: string;
  error?: string;
  requestId?: string;
}

export interface RealtimeTranscriptionResult {
  success: boolean;
  text: string;
  error?: string;
  isEnd?: boolean;
}

export interface RealtimeTranscriptionCallbacks {
  onResult: (result: RealtimeTranscriptionResult) => void;
  onError: (error: string) => void;
  onConnect: () => void;
  onDisconnect: () => void;
}

/**
 * åç«¯WebSocketè¯­éŸ³è½¬å†™æœåŠ¡
 */
class BackendSpeechService {
  private wsUrl = 'ws://localhost:8080/api/xunzhi/v1/xunfei/audio-to-text';
  private websocket: WebSocket | null = null;
  private callbacks: RealtimeTranscriptionCallbacks | null = null;
  private isConnected: boolean = false;

  /**
   * å»ºç«‹WebSocketè¿æ¥
   */
  async connect(callbacks: RealtimeTranscriptionCallbacks): Promise<boolean> {
    return new Promise((resolve, reject) => {
      try {
        this.callbacks = callbacks;
        
        console.log('ğŸ¤ è¿æ¥åç«¯WebSocket:', this.wsUrl);
        
        this.websocket = new WebSocket(this.wsUrl);
        
        this.websocket.onopen = () => {
          console.log('ğŸ¤ WebSocketè¿æ¥æˆåŠŸ');
          this.isConnected = true;
          callbacks.onConnect();
          resolve(true);
        };
        
        this.websocket.onmessage = (event) => {
          this.handleMessage(event.data);
        };
        
        this.websocket.onerror = (error) => {
          console.error('ğŸ¤ WebSocketé”™è¯¯:', error);
          this.isConnected = false;
          callbacks.onError('WebSocketè¿æ¥é”™è¯¯');
          reject(error);
        };
        
        this.websocket.onclose = (event) => {
          console.log('ğŸ¤ WebSocketè¿æ¥å…³é—­:', event.code, event.reason);
          this.isConnected = false;
          callbacks.onDisconnect();
        };
        
      } catch (error) {
        console.error('ğŸ¤ è¿æ¥å¤±è´¥:', error);
        callbacks.onError('è¿æ¥å¤±è´¥: ' + error);
        reject(error);
      }
    });
  }

  /**
   * å¤„ç†WebSocketæ¶ˆæ¯
   */
  private handleMessage(data: string): void {
    try {
      const response: BackendSpeechResponse = JSON.parse(data);
      console.log('ğŸ¤ æ”¶åˆ°åç«¯æ¶ˆæ¯:', response);
      
      if (!response.success) {
        this.callbacks?.onError(response.error || 'è½¬å†™å¤±è´¥');
        return;
      }
      
      this.callbacks?.onResult({
        success: true,
        text: response.text || '',
        isEnd: response.isEnd || false
      });
      
    } catch (error) {
      console.error('ğŸ¤ è§£ææ¶ˆæ¯å¤±è´¥:', error);
      this.callbacks?.onError('è§£ææ¶ˆæ¯å¤±è´¥');
    }
  }

  /**
   * å‘é€éŸ³é¢‘æ•°æ®
   */
  sendAudioData(audioData: ArrayBuffer): void {
    if (!this.isConnected || !this.websocket) {
      console.warn('ğŸ¤ WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€éŸ³é¢‘æ•°æ®');
      return;
    }
    
    try {
      // ç›´æ¥å‘é€äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
      this.websocket.send(audioData);
    } catch (error) {
      console.error('ğŸ¤ å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', error);
      this.callbacks?.onError('å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥');
    }
  }

  /**
   * å‘é€ç»“æŸæ ‡è¯†
   */
  sendEndSignal(): void {
    if (!this.isConnected || !this.websocket) {
      return;
    }
    
    try {
      // å‘é€ç©ºçš„ArrayBufferè¡¨ç¤ºç»“æŸ
      const endBuffer = new ArrayBuffer(0);
      this.websocket.send(endBuffer);
      console.log('ğŸ¤ å‘é€ç»“æŸæ ‡è¯†');
    } catch (error) {
      console.error('ğŸ¤ å‘é€ç»“æŸæ ‡è¯†å¤±è´¥:', error);
    }
  }

  /**
   * æ–­å¼€è¿æ¥
   */
  disconnect(): void {
    if (this.websocket) {
      this.websocket.close(1000, 'Normal closure');
      this.websocket = null;
    }
    this.isConnected = false;
    this.callbacks = null;
  }

  /**
   * æ£€æŸ¥è¿æ¥çŠ¶æ€
   */
  isWebSocketConnected(): boolean {
    return this.isConnected && this.websocket?.readyState === WebSocket.OPEN;
  }
}

// å¯¼å‡ºå®ä¾‹
export const backendSpeechService = new BackendSpeechService();

// ä¿ç•™åŸæœ‰çš„åŒæ­¥æ¥å£ä½œä¸ºå¤‡ç”¨
class XunfeiSpeechService {
  private readonly baseUrl = '/api/xunzhi/v1/xunfei';

  /**
   * å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡å­—
   * @param audioFile éŸ³é¢‘æ–‡ä»¶ (Blob)
   * @returns Promise<SpeechToTextResult>
   */
  async audioToText(audioFile: Blob): Promise<SpeechToTextResult> {
    try {
      console.log('ğŸ¤ [xunfeiSpeechService] å¼€å§‹è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚:', {
        fileSize: audioFile.size,
        fileType: audioFile.type,
        url: `${this.baseUrl}/audio-transcribe`
      });

      // åˆ›å»º FormData å¯¹è±¡
      const formData = new FormData();
      
      // æ ¹æ®éŸ³é¢‘ç±»å‹è®¾ç½®æ–‡ä»¶å
      let fileName = 'audio.webm';
      if (audioFile.type.includes('wav')) {
        fileName = 'audio.wav';
      } else if (audioFile.type.includes('mp3')) {
        fileName = 'audio.mp3';
      } else if (audioFile.type.includes('ogg')) {
        fileName = 'audio.ogg';
      } else if (audioFile.type.includes('m4a')) {
        fileName = 'audio.m4a';
      }
      
      formData.append('file', audioFile, fileName);
      console.log('ğŸ¤ [xunfeiSpeechService] FormDataå‡†å¤‡å®Œæˆ, fileName:', fileName);

      // å‘é€è¯·æ±‚åˆ°è®¯é£æ¥å£ - ä½¿ç”¨é¡¹ç›®çš„requestå®ä¾‹ç¡®ä¿è‡ªåŠ¨å¸¦ä¸Štoken
      console.log('ğŸ¤ [xunfeiSpeechService] å‘é€APIè¯·æ±‚...');
      const response = await request.post<XunfeiSpeechToTextResponse>(
        '/xunzhi/v1/xunfei/audio-transcribe',
        formData,
        {
          headers: {
            // è®©æµè§ˆå™¨è‡ªåŠ¨è®¾ç½® Content-Type ä¸º multipart/form-data
            'Content-Type': undefined,
          },
        }
      );

      console.log('ğŸ¤ [xunfeiSpeechService] APIå“åº”æ•°æ®:', response);

      // æ£€æŸ¥å“åº”çŠ¶æ€
      if (!response.success || response.code !== '0') {
        console.error('ğŸ¤ [xunfeiSpeechService] APIè¿”å›é”™è¯¯:', response);
        return {
          success: false,
          text: '',
          error: response.data?.errorMessage || response.message || 'è¯­éŸ³è½¬æ–‡å­—å¤±è´¥',
          requestId: response.data?.requestId || response.requestId
        };
      }

      // æ£€æŸ¥å†…éƒ¨æ•°æ®çŠ¶æ€
      if (!response.data?.success) {
        console.error('ğŸ¤ [xunfeiSpeechService] è½¬å†™å¤±è´¥:', response.data);
        return {
          success: false,
          text: '',
          error: response.data?.errorMessage || 'è¯­éŸ³è½¬æ–‡å­—å¤±è´¥',
          requestId: response.data?.requestId
        };
      }

      // æå–è½¬æ¢åçš„æ–‡å­—
      const text = response.data.transcriptionText || '';
      console.log('ğŸ¤ [xunfeiSpeechService] è½¬æ¢æˆåŠŸ, æ–‡å­—å†…å®¹:', text);
      console.log('ğŸ¤ [xunfeiSpeechService] è½¬æ¢è¯¦æƒ…:', {
        audioFileSize: response.data.audioFileSize,
        audioFormat: response.data.audioFormat,
        transcriptionDuration: response.data.transcriptionDuration,
        language: response.data.language,
        confidence: response.data.confidence
      });

      return {
        success: true,
        text: text || 'æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹',
        requestId: response.data.requestId
      };

    } catch (error) {
      console.error('ğŸ¤ [xunfeiSpeechService] è®¯é£è¯­éŸ³è½¬æ–‡å­—æœåŠ¡é”™è¯¯:', error);
      return {
        success: false,
        text: '',
        error: error instanceof Error ? error.message : 'ç½‘ç»œè¯·æ±‚å¤±è´¥'
      };
    }
  }

  /**
   * æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
   * @param file éŸ³é¢‘æ–‡ä»¶
   * @returns boolean
   */
  isSupportedAudioFormat(file: Blob): boolean {
    const supportedTypes = [
      'audio/webm',
      'audio/wav',
      'audio/mp3',
      'audio/ogg',
      'audio/m4a'
    ];

    return supportedTypes.includes(file.type);
  }

  /**
   * è·å–éŸ³é¢‘æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆå­—èŠ‚ï¼‰
   * @returns number
   */
  getMaxFileSize(): number {
    // è®¾ç½®æœ€å¤§æ–‡ä»¶å¤§å°ä¸º 10MB
    return 10 * 1024 * 1024;
  }

  /**
   * éªŒè¯éŸ³é¢‘æ–‡ä»¶
   * @param file éŸ³é¢‘æ–‡ä»¶
   * @returns { valid: boolean, error?: string }
   */
  validateAudioFile(file: Blob): { valid: boolean; error?: string } {
    if (!file) {
      return { valid: false, error: 'éŸ³é¢‘æ–‡ä»¶ä¸èƒ½ä¸ºç©º' };
    }

    if (file.size === 0) {
      return { valid: false, error: 'éŸ³é¢‘æ–‡ä»¶å¤§å°ä¸èƒ½ä¸º0' };
    }

    if (file.size > this.getMaxFileSize()) {
      return { valid: false, error: 'éŸ³é¢‘æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§10MBï¼‰' };
    }

    if (!this.isSupportedAudioFormat(file)) {
      return { valid: false, error: 'ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼' };
    }

    return { valid: true };
  }
}

// å¯¼å‡ºXunfeiSpeechServiceå®ä¾‹
export const xunfeiSpeechService = new XunfeiSpeechService();