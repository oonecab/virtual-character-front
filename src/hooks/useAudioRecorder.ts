import { useState, useRef, useCallback } from 'react';
import { xunfeiSpeechService, SpeechToTextResult } from '../services/xunfeiSpeechService';
import { AudioConverter } from '../utils/audioConverter';

export interface AudioRecorderState {
  isRecording: boolean;
  isProcessing: boolean;
  error: string | null;
  audioBlob: Blob | null;
  duration: number;
}

export interface UseAudioRecorderReturn {
  state: AudioRecorderState;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  convertToText: () => Promise<SpeechToTextResult>;
  clearRecording: () => void;
  resetError: () => void;
}

export const useAudioRecorder = (): UseAudioRecorderReturn => {
  const [state, setState] = useState<AudioRecorderState>({
    isRecording: false,
    isProcessing: false,
    error: null,
    audioBlob: null,
    duration: 0,
  });

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);
  const stateRef = useRef<AudioRecorderState>(state);

  // æ›´æ–°stateRefä»¥ä¿æŒæœ€æ–°çŠ¶æ€
  stateRef.current = state;

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      // é‡ç½®çŠ¶æ€
      setState(prev => ({
        ...prev,
        isRecording: false,
        isProcessing: true,
        error: null,
        audioBlob: null,
        duration: 0,
      }));

      // è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000, // è®¯é£æ¨èçš„é‡‡æ ·ç‡
        },
      });

      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼Œä¼˜å…ˆä½¿ç”¨WAVæ ¼å¼
      const mimeTypes = [
        'audio/wav',
        'audio/webm;codecs=pcm',
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
      ];

      let selectedMimeType = '';
      for (const mimeType of mimeTypes) {
        if (MediaRecorder.isTypeSupported(mimeType)) {
          selectedMimeType = mimeType;
          console.log('ğŸ¤ é€‰æ‹©çš„éŸ³é¢‘æ ¼å¼:', selectedMimeType);
          break;
        }
      }

      if (!selectedMimeType) {
        throw new Error('æµè§ˆå™¨ä¸æ”¯æŒä»»ä½•éŸ³é¢‘å½•åˆ¶æ ¼å¼');
      }

      // åˆ›å»º MediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: selectedMimeType,
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      startTimeRef.current = Date.now();

      // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
      mediaRecorder.ondataavailable = (event) => {
        console.log('ğŸ¤ æ”¶åˆ°éŸ³é¢‘æ•°æ®:', event.data.size, 'bytes');
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('ğŸ¤ å½“å‰éŸ³é¢‘å—æ€»æ•°:', audioChunksRef.current.length);
        }
      };

      mediaRecorder.onstop = async () => {
        console.log('ğŸ¤ MediaRecorder onstop äº‹ä»¶è§¦å‘');
        console.log('ğŸ¤ éŸ³é¢‘å—æ•°é‡:', audioChunksRef.current.length);
        console.log('ğŸ¤ éŸ³é¢‘å—è¯¦æƒ…:', audioChunksRef.current.map(chunk => ({ size: chunk.size, type: chunk.type })));
        
        if (audioChunksRef.current.length === 0) {
          console.error('ğŸ¤ æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•éŸ³é¢‘æ•°æ®');
          setState(prev => ({
            ...prev,
            isRecording: false,
            isProcessing: false,
            error: 'æ²¡æœ‰å½•åˆ¶åˆ°éŸ³é¢‘æ•°æ®ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™',
          }));
          return;
        }

        const originalBlob = new Blob(audioChunksRef.current, {
          type: selectedMimeType,
        });
        const duration = Date.now() - startTimeRef.current;

        console.log('ğŸ¤ åˆ›å»ºçš„åŸå§‹ audioBlob:', {
          size: originalBlob.size,
          type: originalBlob.type,
          duration
        });

        if (originalBlob.size === 0) {
          console.error('ğŸ¤ åˆ›å»ºçš„éŸ³é¢‘Blobå¤§å°ä¸º0');
          setState(prev => ({
            ...prev,
            isRecording: false,
            isProcessing: false,
            error: 'å½•åˆ¶çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º',
          }));
          return;
        }

        try {
          let finalAudioBlob = originalBlob;

          // å¦‚æœä¸æ˜¯WAVæ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸ºWAV
          if (!selectedMimeType.includes('wav') && AudioConverter.isSupported()) {
            console.log('ğŸ¤ å¼€å§‹è½¬æ¢éŸ³é¢‘æ ¼å¼åˆ°WAV...');
            setState(prev => ({
              ...prev,
              isProcessing: true,
            }));

            try {
              finalAudioBlob = await AudioConverter.webmToWav(originalBlob);
              console.log('ğŸ¤ éŸ³é¢‘æ ¼å¼è½¬æ¢æˆåŠŸ:', {
                originalSize: originalBlob.size,
                originalType: originalBlob.type,
                convertedSize: finalAudioBlob.size,
                convertedType: finalAudioBlob.type
              });
            } catch (convertError) {
              console.warn('ğŸ¤ éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ ¼å¼:', convertError);
              finalAudioBlob = originalBlob;
            }
          }

          setState(prev => {
            console.log('ğŸ¤ æ›´æ–°çŠ¶æ€ï¼Œè®¾ç½® audioBlob');
            console.log('ğŸ¤ prevçŠ¶æ€:', prev);
            console.log('ğŸ¤ è¦è®¾ç½®çš„audioBlob:', finalAudioBlob);
            const newState = {
              ...prev,
              isRecording: false,
              isProcessing: false,
              audioBlob: finalAudioBlob,
              duration,
            };
            console.log('ğŸ¤ æ–°çŠ¶æ€:', newState);
            
            // åŒæ—¶æ›´æ–° stateRef
            stateRef.current = newState;
            console.log('ğŸ¤ å·²æ›´æ–° stateRef.current:', stateRef.current);
            
            return newState;
          });

        } catch (error) {
          console.error('ğŸ¤ å¤„ç†éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯:', error);
          setState(prev => ({
            ...prev,
            isRecording: false,
            isProcessing: false,
            error: 'éŸ³é¢‘å¤„ç†å¤±è´¥',
          }));
        }

        // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
        stream.getTracks().forEach(track => track.stop());
        console.log('ğŸ¤ å·²åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“');
      };

      mediaRecorder.onerror = (event) => {
        console.error('å½•éŸ³é”™è¯¯:', event);
        setState(prev => ({
          ...prev,
          isRecording: false,
          isProcessing: false,
          error: 'å½•éŸ³è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯',
        }));

        // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
        stream.getTracks().forEach(track => track.stop());
      };

      // å¼€å§‹å½•éŸ³
      mediaRecorder.start(100); // æ¯100msæ”¶é›†ä¸€æ¬¡æ•°æ®
      console.log('ğŸ¤ MediaRecorder å·²å¼€å§‹å½•éŸ³ï¼Œtimeslice: 100ms');

      setState(prev => ({
        ...prev,
        isRecording: true,
        isProcessing: false,
        error: null,
      }));

      console.log('ğŸ¤ å½•éŸ³çŠ¶æ€å·²æ›´æ–°ä¸º isRecording: true');

    } catch (error) {
      console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
      let errorMessage = 'å¼€å§‹å½•éŸ³å¤±è´¥';

      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = 'è¯·å…è®¸è®¿é—®éº¦å…‹é£æƒé™';
        } else if (error.name === 'NotFoundError') {
          errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡';
        } else if (error.name === 'NotSupportedError') {
          errorMessage = 'æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½';
        } else {
          errorMessage = error.message;
        }
      }

      setState(prev => ({
        ...prev,
        isRecording: false,
        isProcessing: false,
        error: errorMessage,
      }));
    }
  }, []);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(async () => {
    console.log('ğŸ¤ stopRecording è¢«è°ƒç”¨ï¼Œå½“å‰çŠ¶æ€:', {
      isRecording: stateRef.current.isRecording,
      mediaRecorder: !!mediaRecorderRef.current,
      mediaRecorderState: mediaRecorderRef.current?.state
    });
    
    if (mediaRecorderRef.current && stateRef.current.isRecording) {
      console.log('ğŸ¤ å¼€å§‹åœæ­¢å½•éŸ³...');
      setState(prev => ({
        ...prev,
        isProcessing: true,
      }));

      mediaRecorderRef.current.stop();
      console.log('ğŸ¤ å·²è°ƒç”¨ mediaRecorder.stop()');
    } else {
      console.log('ğŸ¤ æ— æ³•åœæ­¢å½•éŸ³ - mediaRecorder æˆ– isRecording çŠ¶æ€ä¸æ­£ç¡®', {
        hasMediaRecorder: !!mediaRecorderRef.current,
        isRecording: stateRef.current.isRecording,
        mediaRecorderState: mediaRecorderRef.current?.state
      });
    }
  }, []);

  // è½¬æ¢ä¸ºæ–‡å­—
  const convertToText = useCallback(async (): Promise<SpeechToTextResult> => {
    console.log('ğŸ¤ convertToTextè¢«è°ƒç”¨ï¼Œå½“å‰çŠ¶æ€:', state);
    console.log('ğŸ¤ convertToTextè¢«è°ƒç”¨ï¼ŒstateRefçŠ¶æ€:', stateRef.current);
    
    // ç­‰å¾…audioBlobå‡†å¤‡å°±ç»ª
    const maxWaitTime = 3000; // æœ€é•¿ç­‰å¾…3ç§’
    const checkInterval = 100; // æ¯100msæ£€æŸ¥ä¸€æ¬¡
    let waitedTime = 0;

    while (waitedTime < maxWaitTime && !stateRef.current.audioBlob) {
      console.log('ğŸ¤ ç­‰å¾…audioBlobå‡†å¤‡å°±ç»ª...', { 
        waitedTime, 
        hasAudioBlob: !!stateRef.current.audioBlob,
        audioBlobSize: stateRef.current.audioBlob?.size || 0
      });
      await new Promise(resolve => setTimeout(resolve, checkInterval));
      waitedTime += checkInterval;
    }

    if (!stateRef.current.audioBlob) {
      console.error('ğŸ¤ convertToText: audioBlobä»ç„¶ä¸ºnull');
      return {
        success: false,
        text: '',
        error: 'æ²¡æœ‰å¯è½¬æ¢çš„éŸ³é¢‘æ–‡ä»¶',
      };
    }

    console.log('ğŸ¤ audioBlobå‡†å¤‡å°±ç»ªï¼Œå¼€å§‹è½¬æ¢:', {
      size: stateRef.current.audioBlob.size,
      type: stateRef.current.audioBlob.type
    });

    try {
      setState(prev => ({
        ...prev,
        isProcessing: true,
        error: null,
      }));

      // éªŒè¯éŸ³é¢‘æ–‡ä»¶
      const validation = xunfeiSpeechService.validateAudioFile(stateRef.current.audioBlob);
      if (!validation.valid) {
        setState(prev => ({
          ...prev,
          isProcessing: false,
          error: validation.error || 'éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥',
        }));

        return {
          success: false,
          text: '',
          error: validation.error || 'éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥',
        };
      }

      // è°ƒç”¨è®¯é£è¯­éŸ³è½¬æ–‡å­—æœåŠ¡
      const result = await xunfeiSpeechService.audioToText(stateRef.current.audioBlob);

      setState(prev => ({
        ...prev,
        isProcessing: false,
        error: result.success ? null : result.error || 'è½¬æ¢å¤±è´¥',
      }));

      return result;

    } catch (error) {
      console.error('è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error);
      const errorMessage = error instanceof Error ? error.message : 'è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯';

      setState(prev => ({
        ...prev,
        isProcessing: false,
        error: errorMessage,
      }));

      return {
        success: false,
        text: '',
        error: errorMessage,
      };
    }
  }, [state.audioBlob]);

  // æ¸…é™¤å½•éŸ³
  const clearRecording = useCallback(() => {
    setState(prev => ({
      ...prev,
      audioBlob: null,
      duration: 0,
      error: null,
    }));
    audioChunksRef.current = [];
  }, []);

  // é‡ç½®é”™è¯¯
  const resetError = useCallback(() => {
    setState(prev => ({
      ...prev,
      error: null,
    }));
  }, []);

  return {
    state,
    startRecording,
    stopRecording,
    convertToText,
    clearRecording,
    resetError,
  };
};